{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnn.search_cnn import  SearchCNN, SearchCNNController\n",
    "from models.cnn_darts_hypernet.search_cnn_darts_hypernet import  SearchCNNControllerWithHyperNet\n",
    "\n",
    "from configobj import ConfigObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basecfg_path = '../../configs/hyper/fmnist.cfg'  #конфиг, на который мы ориентируемся при загрузки модели\n",
    "\n",
    "\n",
    "\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "name = cfg['name'] # имя для сохранения результатов\n",
    "ckp_path = '../../searchs/fmnist_darts/checkpoint_{}_49.ckp' # это шаблон названия сохраненных моделей\n",
    "seeds = cfg['seeds'].split(';')  # сиды. можно брать из конфига\n",
    "fine_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "# get data with meta info\n",
    "input_size, input_channels, n_classes, train_data, valid_data = utils.get_data(\n",
    "    'fashionmnist', '../../data/', cutout_length=0, validation=True)\n",
    "\n",
    "# split data to train/validation\n",
    "n_train = len(train_data)\n",
    "split = int(n_train * 0.5)\n",
    "indices = list(range(n_train))\n",
    "\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(\n",
    "    indices[:split])\n",
    "valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(\n",
    "    indices[split:])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                        batch_size=64,\n",
    "                                        sampler=train_sampler,\n",
    "                                        num_workers=1,\n",
    "                                        pin_memory=True)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                        batch_size=64,\n",
    "                                        sampler=valid_sampler,\n",
    "                                        num_workers=1,\n",
    "                                        pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(valid_data,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=1,\n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_structure(sc): # во время тестов нашей модели нужно перейти от непрерывной структуры к one-hot\n",
    "    for alpha in sc.alpha_reduce:\n",
    "        alpha.requires_grad = False\n",
    "        for subalpha in alpha:\n",
    "            \n",
    "            argm = torch.argmax(subalpha)\n",
    "            subalpha.data*=0\n",
    "            subalpha.data[argm] += 1\n",
    "    sc.sampling_mode = 'naive'\n",
    "            \n",
    "def calc_param_number(sc):\n",
    "    penalty = 0\n",
    "    for id, cell in enumerate(sc.net.cells):\n",
    "            # можно не пробегать несколько раз, т.к. клетки одинаковы (С точностью до normal и reduce)                        \n",
    "            weights = [alpha for alpha in sc.alpha_reduce] if cell.reduction else [\n",
    "                alpha for alpha in sc.alpha_normal]        \n",
    "            \n",
    "            for edges, w_list in zip(cell.dag, weights):\n",
    "                for mixed_op, weights in zip(edges, w_list):\n",
    "                    for op, w in zip(mixed_op._ops, weights):                        \n",
    "                        for param in op.parameters():\n",
    "                            penalty += w*np.prod(param.shape) \n",
    "    return penalty            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:11<00:00, 42.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8997, device='cuda:0')\n",
      "seed 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:11<00:00, 41.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8976, device='cuda:0')\n",
      "seed 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:11<00:00, 42.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9011, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# смотрим качество модели, которое мы получили на обучении, без фиксации структуры, но с переводом на обычный DARTS\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "cfg['device'] = 'cuda'\n",
    "for s in seeds:\n",
    "    print ('seed {}'.format(s))\n",
    "    sc = SearchCNNController(**cfg)        \n",
    "    sc.load_state_dict(torch.load(ckp_path.format(s)))     \n",
    "    sc = sc.to('cuda')        \n",
    "    sc.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x,y in tqdm.tqdm(valid_loader):\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        out = sc(x)\n",
    "        correct += torch.eq(torch.argmax(out, 1), y).sum()\n",
    "        total += len(x)\n",
    "    print (correct*1.0/total*1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:10<00:00, 43.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0856, device='cuda:0')\n",
      "tensor(12496., device='cuda:0')\n",
      "seed 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:10<00:00, 43.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0886, device='cuda:0')\n",
      "tensor(12352., device='cuda:0')\n",
      "seed 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:10<00:00, 42.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2225, device='cuda:0')\n",
      "tensor(13120., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# смотрим качество модели, которое мы получили на обучении, без фиксации структуры, но с переводом на обычный DARTS\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "cfg['device'] = 'cuda'\n",
    "for s in seeds:\n",
    "    print ('seed {}'.format(s))\n",
    "    sc = SearchCNNController(**cfg)        \n",
    "    sc.load_state_dict(torch.load(ckp_path.format(s)))     \n",
    "    sc = sc.to('cuda')   \n",
    "    fix_structure(sc)\n",
    "    sc.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x,y in tqdm.tqdm(valid_loader):\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        out = sc(x)\n",
    "        correct += torch.eq(torch.argmax(out, 1), y).sum()\n",
    "        total += len(x)\n",
    "    print (correct*1.0/total*1.0)\n",
    "    print (calc_param_number(sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class HackedNNController(SearchCNNController):\n",
    "    def __init__(self, **kwargs):\n",
    "        SearchCNNController.__init__(self, **kwargs)\n",
    "        self.lam = 0.0\n",
    "        \n",
    "    def loss(self, X, y):\n",
    "        logits = self.forward(X)\n",
    "        penalty = 0\n",
    "        for id, cell in enumerate(self.net.cells):            \n",
    "            \n",
    "            weights = [alpha for alpha in self.alpha_reduce] if cell.reduction else [\n",
    "                alpha for alpha in self.alpha_normal]\n",
    "\n",
    "            weights = [F.softmax(w/self.t, dim=-1) for w in weights]\n",
    "\n",
    "            for edges, w_list in zip(cell.dag, weights):\n",
    "                for mixed_op, weights in zip(edges, w_list):\n",
    "                    for op, w in zip(mixed_op._ops, weights):\n",
    "                        for param in op.parameters():\n",
    "                            penalty += w*np.prod(param.shape)           \n",
    "\n",
    "        return self.criterion(logits, y)   + penalty * self.lam[0,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.37684387: : 469it [02:31,  3.10it/s]\n",
      "0.6799999999999999;0.37178084: : 469it [02:39,  2.94it/s]\n",
      "0.52;0.40263748: : 469it [02:36,  3.00it/s]              \n",
      "0.35999999999999993;0.4215558: : 469it [02:36,  2.99it/s] \n",
      "0.2;0.43260792: : 469it [02:40,  2.92it/s]                \n",
      "100%|██████████| 469/469 [00:11<00:00, 41.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: 1e-08\n",
      "tensor(0.8324, device='cuda:0')\n",
      "param num tensor(11040., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.3811183: : 469it [02:41,  2.90it/s] \n",
      "0.6799999999999999;0.3699376: : 469it [02:40,  2.91it/s] \n",
      "0.52;0.4135063: : 469it [02:41,  2.91it/s]               \n",
      "0.35999999999999993;0.4480036: : 469it [02:41,  2.91it/s] \n",
      "0.2;0.47684354: : 469it [02:41,  2.90it/s]                \n",
      "100%|██████████| 469/469 [00:11<00:00, 41.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 13, lam: 1e-08\n",
      "tensor(0.8384, device='cuda:0')\n",
      "param num tensor(10128., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.38550937: : 469it [02:41,  2.91it/s]\n",
      "0.6799999999999999;0.37989107: : 469it [02:41,  2.90it/s]\n",
      "0.52;0.41088405: : 469it [02:41,  2.91it/s]              \n",
      "0.35999999999999993;0.4422571: : 469it [02:41,  2.90it/s] \n",
      "0.2;0.4486926: : 469it [02:40,  2.91it/s]                 \n",
      "100%|██████████| 469/469 [00:11<00:00, 41.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 21, lam: 1e-08\n",
      "tensor(0.8389, device='cuda:0')\n",
      "param num tensor(11808., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.37633765: : 469it [02:41,  2.90it/s]\n",
      "0.6799999999999999;0.37092686: : 469it [02:41,  2.91it/s]\n",
      "0.52;0.403047: : 469it [02:40,  2.92it/s]                \n",
      "0.35999999999999993;0.4378077: : 469it [02:41,  2.91it/s] \n",
      "0.2;0.43894133: : 469it [02:41,  2.91it/s]                \n",
      "100%|██████████| 469/469 [00:11<00:00, 41.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: 1e-07\n",
      "tensor(0.8454, device='cuda:0')\n",
      "param num tensor(11040., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.383313: : 469it [02:41,  2.91it/s]  \n",
      "0.6799999999999999;0.3754614: : 469it [02:41,  2.91it/s] \n",
      "0.52;0.40271854: : 469it [02:41,  2.91it/s]              \n",
      "0.35999999999999993;0.448941: : 469it [02:41,  2.90it/s]  \n",
      "0.2;0.4706503: : 469it [02:41,  2.90it/s]                 \n",
      "100%|██████████| 469/469 [00:11<00:00, 41.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 13, lam: 1e-07\n",
      "tensor(0.8088, device='cuda:0')\n",
      "param num tensor(9616., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.38738075: : 469it [02:41,  2.90it/s]\n",
      "0.6799999999999999;0.37609303: : 469it [02:40,  2.91it/s]\n",
      "0.52;0.40970162: : 469it [02:41,  2.91it/s]              \n",
      "0.35999999999999993;0.4445109: : 469it [02:41,  2.91it/s] \n",
      "0.2;0.45687944: : 469it [02:41,  2.91it/s]                \n",
      "100%|██████████| 469/469 [00:11<00:00, 41.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 21, lam: 1e-07\n",
      "tensor(0.8318, device='cuda:0')\n",
      "param num tensor(10896., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.38372692: : 469it [02:41,  2.91it/s]\n",
      "0.6799999999999999;0.38254455: : 469it [02:41,  2.90it/s]\n",
      "0.52;0.4179877: : 469it [02:41,  2.90it/s]               \n",
      "0.35999999999999993;0.44831303: : 469it [02:41,  2.90it/s]\n",
      "0.2;0.44789633: : 469it [02:41,  2.91it/s]                \n",
      "100%|██████████| 469/469 [00:11<00:00, 41.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: 1e-06\n",
      "tensor(0.8330, device='cuda:0')\n",
      "param num tensor(11040., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.38843343: : 469it [02:41,  2.90it/s]\n",
      "0.6799999999999999;0.37935135: : 469it [02:41,  2.90it/s]\n",
      "0.52;0.41520765: : 469it [02:41,  2.91it/s]              \n",
      "0.35999999999999993;0.4513578: : 469it [02:41,  2.91it/s] \n",
      "0.2;0.47515437: : 469it [02:41,  2.90it/s]                \n",
      "100%|██████████| 469/469 [00:11<00:00, 41.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 13, lam: 1e-06\n",
      "tensor(0.8138, device='cuda:0')\n",
      "param num tensor(9984., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.3943096: : 469it [02:41,  2.90it/s] \n",
      "0.6799999999999999;0.39136225: : 469it [02:41,  2.91it/s]\n",
      "0.52;0.408577: : 469it [02:41,  2.91it/s]                \n",
      "0.35999999999999993;0.44473007: : 469it [02:41,  2.91it/s]\n",
      "0.2;0.4567476: : 469it [02:41,  2.91it/s]                 \n",
      "100%|██████████| 469/469 [00:11<00:00, 41.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 21, lam: 1e-06\n",
      "tensor(0.7576, device='cuda:0')\n",
      "param num tensor(11808., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.4639917: : 469it [02:41,  2.90it/s] \n",
      "0.6799999999999999;0.4606934: : 469it [02:41,  2.91it/s] \n",
      "0.5735607675906185;0.50101376: : 312it [01:46,  2.88it/s]"
     ]
    }
   ],
   "source": [
    "# попробуем дообучить модельки с GS при фиксированной лямбде\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "cfg['device'] = 'cuda'\n",
    "for lam_ in range(-8, -3):    \n",
    "    lam_ = 10.0**(lam_)\n",
    "    lam = torch.tensor([[lam_]]).cuda()\n",
    "    \n",
    "    def hyperloss(self, X, y):\n",
    "        logits = self.forward(X, lam)\n",
    "        penalty = 0\n",
    "        for id, cell in enumerate(self.net.cells):            \n",
    "            \n",
    "            weights = [alpha for alpha in self.hyper_reduce] if cell.reduction else [\n",
    "                alpha for alpha in self.hyper_normal]\n",
    "\n",
    "            weights = [F.softmax(w/self.t, dim=-1) for w in weights]\n",
    "\n",
    "            for edges, w_list in zip(cell.dag, weights):\n",
    "                for mixed_op, weights in zip(edges, w_list):\n",
    "                    for op, w in zip(mixed_op._ops, weights):\n",
    "                        for param in op.parameters():\n",
    "                            penalty += w*np.prod(param.shape)           \n",
    "\n",
    "        return self.criterion(logits, y)   + penalty * lam[0,0] \n",
    "\n",
    "        \n",
    "    for s in seeds:\n",
    "       \n",
    "        sc0 = HackedNNController(**cfg)        \n",
    "        sc0.load_state_dict(torch.load(ckp_path.format(s)))     \n",
    "        sc0 = sc0.to('cuda')\n",
    "        sc0.samling_mode='gumbel-softmax'\n",
    "        sc0.lam = lam\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "        batch_id = 0\n",
    "        for e in range(fine_epochs//2):\n",
    "            tq = tqdm.tqdm((zip(train_loader, valid_loader)))\n",
    "            losses = []\n",
    "            for ((trn_X, trn_y), (val_X, val_y)) in tq:\n",
    "                batch_id += 1                \n",
    "                t = 0.2 + (0.8 - 0.8 * batch_id/(fine_epochs//2*len(train_loader)))\n",
    "                sc0.t = t\n",
    "                trn_X, trn_y = trn_X.to('cuda', non_blocking=True), trn_y.to('cuda', non_blocking=True)\n",
    "                val_X, val_y = val_X.to('cuda', non_blocking=True), val_y.to('cuda', non_blocking=True)                 \n",
    "                loss = sc0.train_step(trn_X, trn_y, val_X, val_y).detach().cpu().numpy()\n",
    "                losses.append(loss)\n",
    "                tq.set_description('{};{}'.format(sc0.t, str(np.mean(losses))))\n",
    "                \n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "        fix_structure(sc0)\n",
    "        sc0.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for x,y in tqdm.tqdm(valid_loader):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            out = sc0(x)\n",
    "            correct += torch.eq(torch.argmax(out, 1), y).sum()\n",
    "            total += len(x)\n",
    "        \n",
    "        penalty = calc_param_number(sc0)        \n",
    "        print ('seed {}, lam: {}'.format(s, lam_))\n",
    "        print (correct*1.0/total*1.0)\n",
    "        print ('param num', penalty)\n",
    "        print ('\\n'*3)\n",
    "        torch.save(sc0.state_dict(), 'darts_{}_prefine_lam_{}.pth'.format(s, lam_ ))\n",
    "                            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.hyperloss(self, X, y)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc0.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_0_prefine_lam_0.001.pth'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'model_{}_prefine_lam_{}.pth'.format(s, lam_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0407e+00, -2.5080e+00, -4.8985e+00,  6.0774e+00,  1.1547e-01,\n",
       "         -1.7027e+00, -4.5315e-01,  8.9518e+00, -4.7982e+00,  2.8806e+00],\n",
       "        [-2.4257e+00, -1.9611e-01, -6.0386e+00,  9.4664e-03, -4.2474e+00,\n",
       "         -1.2515e+00,  1.2721e-01,  8.6204e+00,  6.9197e-01,  5.5956e+00],\n",
       "        [ 2.1178e+00, -5.2917e-01,  4.5798e+00,  1.0271e-01, -5.7425e+00,\n",
       "         -7.9479e+00,  3.9173e+00,  1.7867e+00, -3.9782e-01,  2.3104e+00],\n",
       "        [ 3.5477e+00,  1.9448e+00,  8.7270e+00,  1.7255e+00, -6.4827e+00,\n",
       "         -9.9263e+00, -3.4194e-01,  1.1371e+00,  6.0196e+00, -5.7826e+00],\n",
       "        [-6.3454e-01, -7.4744e-01,  1.8433e+00,  4.2400e+00, -7.6684e+00,\n",
       "         -3.7727e+00,  3.5501e+00,  3.1300e+00, -6.1671e+00,  7.1702e+00],\n",
       "        [-2.3435e+00, -7.0764e-01, -4.9570e+00, -9.3269e-01, -4.9343e+00,\n",
       "         -2.6882e+00,  7.4749e-01,  8.8085e+00,  1.3677e+00,  6.1104e+00],\n",
       "        [ 1.5993e+00,  3.2610e+00,  5.3848e+00, -6.0362e-02, -7.3853e+00,\n",
       "         -8.0302e+00, -3.8744e-01,  2.3323e+00,  4.9857e+00, -1.1310e+00],\n",
       "        [-2.3331e+00,  6.2565e-01, -2.7047e+00,  2.3790e-01, -3.9594e+00,\n",
       "         -3.2803e+00, -1.2022e+00,  7.6270e+00,  4.4128e+00,  1.3428e+00],\n",
       "        [-1.1010e+00, -1.8707e+00, -1.9237e+00,  4.0322e+00, -1.9329e+00,\n",
       "         -3.2666e+00,  1.7963e+00,  5.4837e+00, -2.4222e+00,  2.3212e+00],\n",
       "        [-1.0485e+00,  1.3766e-01, -1.2706e+00,  5.1692e+00, -3.2115e+00,\n",
       "         -4.2548e+00,  3.1289e-01,  7.2412e+00, -3.9237e+00,  1.8255e+00],\n",
       "        [-6.2931e-01,  1.4951e+00,  1.7133e+00,  4.9864e+00, -3.1393e+00,\n",
       "         -4.4854e+00, -2.3053e+00,  5.9496e+00, -2.2628e+00,  4.1004e-01],\n",
       "        [ 3.4306e-01, -5.5602e-01, -9.6802e-01,  3.0497e+00, -4.1894e+00,\n",
       "         -5.3129e+00,  2.3293e+00,  6.2756e+00, -3.3921e+00,  2.8655e+00],\n",
       "        [ 4.1515e-01,  5.3591e-01,  1.5520e+00,  3.3836e-02, -5.0329e+00,\n",
       "         -4.1140e+00,  3.7999e-01,  2.8028e+00,  2.3550e+00,  1.9781e+00],\n",
       "        [ 9.3773e-01, -2.9691e-01, -1.3723e+00,  1.2717e+00, -4.4760e+00,\n",
       "         -3.4008e+00, -6.8913e-01,  5.8527e+00,  2.2216e+00,  7.0954e-01],\n",
       "        [ 1.1909e+00, -2.3558e+00,  1.3868e+00,  3.8269e+00, -2.4439e+00,\n",
       "         -6.8694e+00,  2.2785e-01,  6.2846e+00, -9.3201e-02, -1.6131e-01],\n",
       "        [ 4.3680e+00, -1.4989e+00,  2.6517e+00, -1.9016e+00, -7.2652e+00,\n",
       "         -8.0112e+00,  3.4226e+00,  3.6725e+00,  2.5154e+00,  1.7718e+00]],\n",
       "       device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sc(x) - sc0(x, torch.tensor([10e-9]).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8079, -0.9030, -0.6230, -0.2134,  3.2586, -0.3532, -0.4448, -0.4817],\n",
       "         [-0.8494, -0.8544, -0.6758, -0.5583,  4.6323, -0.5762, -0.6024, -0.5743]],\n",
       "        grad_fn=<ViewBackward>),\n",
       " tensor([[-1.0875, -1.2262, -0.8786, -0.3082,  4.5715, -0.4987, -0.6206, -0.6553],\n",
       "         [-1.1367, -1.1572, -0.9096, -0.7862,  6.3077, -0.7849, -0.8311, -0.7623]],\n",
       "        grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc0.hyper_reduce[0](torch.tensor([0.0])), sc0.hyper_reduce[0](torch.tensor([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.2796],\n",
       "         [-0.3232],\n",
       "         [-0.2557],\n",
       "         [-0.0948],\n",
       "         [ 1.3129],\n",
       "         [-0.1455],\n",
       "         [-0.1758],\n",
       "         [-0.1736],\n",
       "         [-0.2873],\n",
       "         [-0.3027],\n",
       "         [-0.2337],\n",
       "         [-0.2279],\n",
       "         [ 1.6754],\n",
       "         [-0.2087],\n",
       "         [-0.2287],\n",
       "         [-0.1880]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.8079, -0.9030, -0.6230, -0.2134,  3.2586, -0.3532, -0.4448, -0.4817,\n",
       "         -0.8494, -0.8544, -0.6758, -0.5583,  4.6323, -0.5762, -0.6024, -0.5743],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc0.hyper_reduce[0].model[0].weight, sc0.hyper_reduce[0].model[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0., -0., 0., -0., 0., 0., -0., 1.],\n",
      "        [-0., -0., -0., -0., -0., 0., 0., 1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[-0., -0., -0., 0., -0., 0., -0., 1.],\n",
      "        [-0., -0., -0., 0., -0., 0., -0., 1.],\n",
      "        [1., -0., 0., 0., 0., -0., -0., 0.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[-0., 0., -0., -0., 0., -0., -0., 1.],\n",
      "        [-0., -0., 0., -0., -0., -0., -0., 1.],\n",
      "        [-0., -0., 0., -0., 1., -0., -0., 0.],\n",
      "        [-0., -0., 0., 0., 0., 0., -0., 1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[0., 0., -0., -0., -0., -0., -0., 1.],\n",
      "        [-0., -0., -0., -0., -0., -0., -0., 1.],\n",
      "        [-0., -0., 0., -0., 1., -0., -0., 0.],\n",
      "        [0., 0., 0., -0., -0., -0., -0., 1.],\n",
      "        [0., 0., -0., -0., 1., 0., -0., -0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "lam_ = 0.0\n",
    "for h,a in zip(sc0.hyper_reduce, sc.alpha_reduce):\n",
    "                a.data = torch.clone(h(torch.tensor([lam_]).cuda())) \n",
    "       \n",
    "fix_structure(sc)\n",
    "for a in sc.alpha_reduce:\n",
    "    print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0., -0., 0., -0., 0., 0., -0., 1.],\n",
      "        [-0., -0., -0., -0., -0., 0., 0., 1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[-0., -0., -0., 0., -0., 0., -0., 1.],\n",
      "        [-0., -0., -0., 0., -0., 0., -0., 1.],\n",
      "        [0., -0., 0., 0., -0., -0., -0., 1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[-0., 0., -0., -0., 0., -0., -0., 1.],\n",
      "        [-0., -0., 0., -0., -0., -0., -0., 1.],\n",
      "        [-0., -0., 0., -0., 0., -0., -0., 1.],\n",
      "        [-0., -0., 0., -0., 0., 0., -0., 1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[0., 0., -0., -0., -0., -0., -0., 1.],\n",
      "        [-0., -0., -0., -0., -0., -0., -0., 1.],\n",
      "        [0., 0., 0., -0., 0., -0., -0., 1.],\n",
      "        [0., 0., 0., -0., -0., -0., -0., 1.],\n",
      "        [1., 0., -0., -0., 0., 0., -0., -0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "lam_ = 1.0\n",
    "for h,a in zip(sc0.hyper_reduce, sc.alpha_reduce):\n",
    "                a.data = torch.clone(h(torch.tensor([lam_]).cuda()) )\n",
    "       \n",
    "fix_structure(sc)\n",
    "for a in sc.alpha_reduce:\n",
    "    print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def hyperloss(self, X, y, lam):\n",
    "        #logits = self.forward(X, lam)\n",
    "        penalty = 0\n",
    "        \n",
    "        for id, cell in enumerate(self.net.cells):\n",
    "            # можно не пробегать несколько раз, т.к. клетки одинаковы (С точностью до normal и reduce)            \n",
    "            \n",
    "            lam_ = self.norm_lam(lam)\n",
    "            weights = [alpha(lam_) for alpha in self.hyper_reduce] if cell.reduction else [\n",
    "                alpha(lam_) for alpha in self.hyper_normal]\n",
    "            \n",
    "            weights = [F.softmax(w/self.t, dim=-1) for w in weights]\n",
    "            \n",
    "              \n",
    "            for edges, w_list in zip(cell.dag, weights):\n",
    "                for mixed_op, weights in zip(edges, w_list):\n",
    "                    for op, w in zip(mixed_op._ops, weights):                        \n",
    "                        for param in op.parameters():\n",
    "                            penalty += w*np.prod(param.shape)          \n",
    "            #penalty += lam_[0,0] * (torch.norm(self.net.linear.weight)**2 + torch.norm(self.net.linear.bias)**2)\n",
    "            #penalty += (1.0-lam_[0,0]) * (torch.norm(self.net.linear2.weight)**2 + torch.norm(self.net.linear2.bias)**2)\n",
    "            \n",
    "\n",
    "        # oleg return self.criterion(logits, y)   + penalty * lam[0,0] \n",
    "        return penalty \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc0 = sc0.cuda()\n",
    "sc0.t = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6328.6978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5707.0322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5262.7612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4670.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3872.0901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3365.1294, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for r in range(-10, -4):\n",
    "    \n",
    "    print (hyperloss(sc0, 0, 0, torch.tensor([[10**r]]).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'64'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 1.1084],\n",
       "         [-0.0756],\n",
       "         [-0.0762],\n",
       "         [-0.0475],\n",
       "         [-0.6884],\n",
       "         [-0.0391],\n",
       "         [-0.0297],\n",
       "         [-0.0831],\n",
       "         [ 1.0998],\n",
       "         [-0.0604],\n",
       "         [-0.0712],\n",
       "         [-0.0253],\n",
       "         [-0.6183],\n",
       "         [-0.0505],\n",
       "         [-0.0459],\n",
       "         [-0.0997]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 1.5646, -0.8272, -0.6284, -0.3190,  1.9144, -0.6870, -0.3635, -1.1838,\n",
       "          1.3121, -0.8585, -0.7832,  0.6159,  1.7367, -0.8624, -0.6465, -1.3189],\n",
       "        device='cuda:0', requires_grad=True))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc0.hyper_reduce[0].model[0].weight, sc0.hyper_reduce[0].model[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: -4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "  3%|▎         | 27/938 [00:02<01:27, 10.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-dc656a98e3d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/bakhteev/var_nas/models/cnn/search_cnn.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/bakhteev/var_nas/models/cnn/search_cnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bad sampling mode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/bakhteev/var_nas/models/cnn/search_cnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, weights_normal, weights_reduce)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_reduce\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mweights_normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/bakhteev/var_nas/models/cnn/search_cells.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, s0, s1, w_dag)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mw_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0ms_cur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_cur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/bakhteev/var_nas/models/cnn/search_cells.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mw_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0ms_cur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_cur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lam_ in [-4.0,  -1.0]:\n",
    "        lam = torch.tensor([10**lam_])\n",
    "        # создаем модель с обязательным указанием, что к структуре не применяется softmax\n",
    "        cfg = ConfigObj(basecfg_path)\n",
    "        cfg['darts']['sampling_mode'] = 'naive' \n",
    "        cfg['device'] = 'cuda'    \n",
    "        for s in seeds:\n",
    "            print (s)\n",
    "            sc0 = SearchCNNControllerWithHyperNet(**cfg)        \n",
    "            sc0.load_state_dict(torch.load(ckp_path.format(s)))                            \n",
    "            sc = SearchCNNController(**cfg)\n",
    "            \n",
    "            sc.net.load_state_dict(sc0.net.state_dict())\n",
    "            for h,a in zip(sc0.hyper_reduce, sc.alpha_reduce):\n",
    "                a.data = torch.clone(h(lam))                                            \n",
    "            fix_structure(sc)\n",
    "            \n",
    "            sc = sc.to('cuda')\n",
    "            optim = torch.optim.Adam(sc.weights())\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # дообучаем n эпох\n",
    "            print ('seed {}, lam: {}'.format(s, lam_))\n",
    "            for e in range(5):\n",
    "                for x,y in tqdm.tqdm(train_loader):\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()            \n",
    "                    optim.zero_grad()\n",
    "                    loss = sc.loss(x,y)\n",
    "                    loss.backward()\n",
    "                    optim.step()                              \n",
    "                \n",
    "                sc.eval()\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for x,y in tqdm.tqdm(valid_loader):\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()\n",
    "                    out = sc(x)\n",
    "                    correct += torch.eq(torch.argmax(out, 1), y).sum()\n",
    "                    total += len(x)\n",
    "                print (correct*1.0/total*1.0)\n",
    "                sc.train()\n",
    "            torch.save(sc.state_dict(), ckp_path.format(s)+'{}.fine'.format(lam_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 21, lam: -4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.77it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0960, device='cuda:0')\n",
      "seed 21, lam: -1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0967, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# смотрим качество модели, которое мы получили на обучении\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "cfg['device'] = 'cuda'\n",
    "for lam_ in [-4.0,  -1.0]:\n",
    "    for s in seeds:\n",
    "        print ('seed {}, lam: {}'.format(s, lam_))\n",
    "        sc = SearchCNNController(**cfg)\n",
    "        \n",
    "        sc.load_state_dict(torch.load(ckp_path.format(s)+'{}.fine'.format(lam_)))\n",
    "        \n",
    "        sc = sc.to('cuda')\n",
    "        sc.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for x,y in tqdm.tqdm(valid_loader):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            out = sc(x)\n",
    "            correct += torch.eq(torch.argmax(out, 1), y).sum()\n",
    "            total += len(x)\n",
    "        print (correct*1.0/total*1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterList(\n",
       "    (0): Parameter containing: [torch.FloatTensor of size 2x8]\n",
       "    (1): Parameter containing: [torch.FloatTensor of size 3x8]\n",
       "    (2): Parameter containing: [torch.FloatTensor of size 4x8]\n",
       "    (3): Parameter containing: [torch.FloatTensor of size 5x8]\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
