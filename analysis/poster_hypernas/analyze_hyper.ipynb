{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnn.search_cnn import  SearchCNN, SearchCNNController\n",
    "from models.cnn_darts_hypernet.search_cnn_darts_hypernet import  SearchCNNControllerWithHyperNet\n",
    "\n",
    "from configobj import ConfigObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basecfg_path = '../../configs/hyper/fmnist_hyper.cfg'  #конфиг, на который мы ориентируемся при загрузки модели\n",
    "\n",
    "\n",
    "\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "name = cfg['name'] # имя для сохранения результатов\n",
    "ckp_path = '../../searchs/fmnist_darts_hypernet/checkpoint_{}_34.ckp' # это шаблон названия сохраненных моделей\n",
    "seeds = cfg['seeds'].split(';')  # сиды. можно брать из конфига\n",
    "fine_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "# get data with meta info\n",
    "input_size, input_channels, n_classes, train_data, valid_data = utils.get_data(\n",
    "    'fashionmnist', '../../data/', cutout_length=0, validation=True)\n",
    "\n",
    "# split data to train/validation\n",
    "n_train = len(train_data)\n",
    "split = int(n_train * 0.5)\n",
    "indices = list(range(n_train))\n",
    "\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(\n",
    "    indices[:split])\n",
    "valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(\n",
    "    indices[split:])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                        batch_size=64,\n",
    "                                        sampler=train_sampler,\n",
    "                                        num_workers=1,\n",
    "                                        pin_memory=True)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                        batch_size=64,\n",
    "                                        sampler=valid_sampler,\n",
    "                                        num_workers=1,\n",
    "                                        pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(valid_data,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=1,\n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45599999999999996"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0-0.016*34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_structure(sc): # во время тестов нашей модели нужно перейти от непрерывной структуры к one-hot\n",
    "    for alpha in sc.alpha_reduce:\n",
    "        alpha.requires_grad = False\n",
    "        for subalpha in alpha:\n",
    "            \n",
    "            argm = torch.argmax(subalpha)\n",
    "            subalpha.data*=0\n",
    "            subalpha.data[argm] += 1\n",
    "    sc.sampling_mode = 'naive'\n",
    "            \n",
    "def calc_param_number(sc):\n",
    "    penalty = 0\n",
    "    for id, cell in enumerate(sc.net.cells):\n",
    "            # можно не пробегать несколько раз, т.к. клетки одинаковы (С точностью до normal и reduce)                        \n",
    "            weights = [alpha for alpha in sc.alpha_reduce] if cell.reduction else [\n",
    "                alpha for alpha in sc.alpha_normal]        \n",
    "            \n",
    "            for edges, w_list in zip(cell.dag, weights):\n",
    "                for mixed_op, weights in zip(edges, w_list):\n",
    "                    for op, w in zip(mixed_op._ops, weights):                        \n",
    "                        for param in op.parameters():\n",
    "                            penalty += w*np.prod(param.shape) \n",
    "    return penalty            \n",
    "\n",
    "def calc_param_number_hyper(sc, lam, t=0.2):\n",
    "    penalty = 0\n",
    "    for id, cell in enumerate(sc.net.cells):\n",
    "            # можно не пробегать несколько раз, т.к. клетки одинаковы (С точностью до normal и reduce)                        \n",
    "            weights = [torch.nn.functional.softmax(alpha(lam)/t) for alpha in sc.hyper_reduce] if cell.reduction else [\n",
    "                torch.nn.functional.softmax(alpha(lam)/t) for alpha in sc.hyper_normal]        \n",
    "            \n",
    "            for edges, w_list in zip(cell.dag, weights):\n",
    "                for mixed_op, weights in zip(edges, w_list):\n",
    "                    for op, w in zip(mixed_op._ops, weights):                        \n",
    "                        for param in op.parameters():\n",
    "                            penalty += w*np.prod(param.shape) \n",
    "    return penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8. , -7.5, -7. , -6.5, -6. , -5.5, -5. , -4.5, -4. ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: 1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 35.17it/s]\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8044, device='cuda:0')\n",
      "tensor([0.], device='cuda:0', dtype=torch.float64) tensor(13795.0771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 0, lam: 3.162277660168379e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.68it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8104, device='cuda:0')\n",
      "tensor([0.1250], device='cuda:0', dtype=torch.float64) tensor(15693.7910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 0, lam: 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.50it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8142, device='cuda:0')\n",
      "tensor([0.2500], device='cuda:0', dtype=torch.float64) tensor(15611.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 0, lam: 3.162277660168379e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.59it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8169, device='cuda:0')\n",
      "tensor([0.3750], device='cuda:0', dtype=torch.float64) tensor(10444.5498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 0, lam: 1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.62it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8169, device='cuda:0')\n",
      "tensor([0.5000], device='cuda:0', dtype=torch.float64) tensor(10728.8066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 0, lam: 3.162277660168379e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.45it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7927, device='cuda:0')\n",
      "tensor([0.6250], device='cuda:0', dtype=torch.float64) tensor(10445.7178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 0, lam: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.61it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7810, device='cuda:0')\n",
      "tensor([0.7500], device='cuda:0', dtype=torch.float64) tensor(8657.3535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 0, lam: 3.1622776601683795e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.62it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7887, device='cuda:0')\n",
      "tensor([0.8750], device='cuda:0', dtype=torch.float64) tensor(826.0460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 0, lam: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.45it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7631, device='cuda:0')\n",
      "tensor([1.], device='cuda:0', dtype=torch.float64) tensor(318.2246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 13, lam: 1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.60it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8023, device='cuda:0')\n",
      "tensor([0.], device='cuda:0', dtype=torch.float64) tensor(10201.3779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 13, lam: 3.162277660168379e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.53it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7991, device='cuda:0')\n",
      "tensor([0.1250], device='cuda:0', dtype=torch.float64) tensor(9810.4287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 13, lam: 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.51it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8035, device='cuda:0')\n",
      "tensor([0.2500], device='cuda:0', dtype=torch.float64) tensor(10335.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 13, lam: 3.162277660168379e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.59it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7980, device='cuda:0')\n",
      "tensor([0.3750], device='cuda:0', dtype=torch.float64) tensor(8913.9814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 13, lam: 1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.60it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7985, device='cuda:0')\n",
      "tensor([0.5000], device='cuda:0', dtype=torch.float64) tensor(8655.8057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 13, lam: 3.162277660168379e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.51it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8029, device='cuda:0')\n",
      "tensor([0.6250], device='cuda:0', dtype=torch.float64) tensor(9520.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 13, lam: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.56it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8041, device='cuda:0')\n",
      "tensor([0.7500], device='cuda:0', dtype=torch.float64) tensor(9144.0254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 13, lam: 3.1622776601683795e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.56it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7952, device='cuda:0')\n",
      "tensor([0.8750], device='cuda:0', dtype=torch.float64) tensor(4152.0713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 13, lam: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.49it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7887, device='cuda:0')\n",
      "tensor([1.], device='cuda:0', dtype=torch.float64) tensor(3324.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 21, lam: 1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.50it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8103, device='cuda:0')\n",
      "tensor([0.], device='cuda:0', dtype=torch.float64) tensor(11879.7441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 21, lam: 3.162277660168379e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.49it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8070, device='cuda:0')\n",
      "tensor([0.1250], device='cuda:0', dtype=torch.float64) tensor(10922.0361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 21, lam: 1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.54it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8052, device='cuda:0')\n",
      "tensor([0.2500], device='cuda:0', dtype=torch.float64) tensor(9484.8428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 21, lam: 3.162277660168379e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.57it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8105, device='cuda:0')\n",
      "tensor([0.3750], device='cuda:0', dtype=torch.float64) tensor(11202.3525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 21, lam: 1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.62it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8109, device='cuda:0')\n",
      "tensor([0.5000], device='cuda:0', dtype=torch.float64) tensor(10896.4893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 21, lam: 3.162277660168379e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.52it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8073, device='cuda:0')\n",
      "tensor([0.6250], device='cuda:0', dtype=torch.float64) tensor(9449.4268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 21, lam: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.66it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8067, device='cuda:0')\n",
      "tensor([0.7500], device='cuda:0', dtype=torch.float64) tensor(8757.8467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 21, lam: 3.1622776601683795e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.55it/s]\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7826, device='cuda:0')\n",
      "tensor([0.8750], device='cuda:0', dtype=torch.float64) tensor(1357.3335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "seed 21, lam: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 34.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7778, device='cuda:0')\n",
      "tensor([1.], device='cuda:0', dtype=torch.float64) tensor(1149.4932, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# смотрим качество модели, которое мы получили на обучении, без фиксации структуры\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "cfg['device'] = 'cuda'\n",
    "sc = SearchCNNControllerWithHyperNet(**cfg)    \n",
    "\n",
    "for s in seeds:\n",
    "    sc.load_state_dict(torch.load(ckp_path.format(s)))\n",
    "    sc = sc.to('cuda')\n",
    "    sc.eval()\n",
    "    for lam_ in np.linspace(-8, -4, 9):\n",
    "        lam_ = 10.0**(lam_)\n",
    "        lam = torch.tensor([lam_]).to('cuda')\n",
    "    \n",
    "        print ('seed {}, lam: {}'.format(s, lam_))\n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for x,y in tqdm.tqdm(valid_loader):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            out = sc(x, lam)\n",
    "            correct += torch.eq(torch.argmax(out, 1), y).sum()\n",
    "            total += len(x)\n",
    "        print (correct*1.0/total*1.0)\n",
    "        print (sc.norm_lam(lam), calc_param_number_hyper(sc, sc.norm_lam(lam), t=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1e-08 tensor(17856., device='cuda:0')\n",
      "0 1e-06 tensor(13008., device='cuda:0')\n",
      "0 0.0001 tensor(256., device='cuda:0')\n",
      "13 1e-08 tensor(13440., device='cuda:0')\n",
      "13 1e-06 tensor(9216., device='cuda:0')\n",
      "13 0.0001 tensor(3024., device='cuda:0')\n",
      "21 1e-08 tensor(15520., device='cuda:0')\n",
      "21 1e-06 tensor(16688., device='cuda:0')\n",
      "21 0.0001 tensor(1312., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "cfg['device'] = 'cuda'\n",
    "sc = SearchCNNControllerWithHyperNet(**cfg)    \n",
    "\n",
    "for s in seeds:\n",
    "    sc.load_state_dict(torch.load(ckp_path.format(s)))\n",
    "    sc = sc.to('cuda')\n",
    "    sc.eval()\n",
    "    sc2 = SearchCNNController(**cfg)\n",
    "    for lam_ in [-8, -6, -4]:\n",
    "        lam_ = 10.0**(lam_)\n",
    "        lam = torch.tensor([lam_]).to('cuda')\n",
    "        \n",
    "        for h,a in zip(sc.hyper_reduce, sc2.alpha_reduce):\n",
    "            a.data = torch.clone((h(sc.norm_lam(lam)) )) \n",
    "        for h,a in zip(sc.hyper_normal, sc2.alpha_normal):\n",
    "            a.data = torch.clone((h(sc.norm_lam(lam)) )) \n",
    "        fix_structure(sc2)\n",
    "        print (s, lam_, calc_param_number(sc2))\n",
    "        structure_list_reduce = []\n",
    "        structure_list_normal = []\n",
    "        for a in sc2.alpha_reduce:\n",
    "            structure_list_reduce.append((torch.argmax(a, 1).cpu().detach().numpy()).tolist())\n",
    "        for a in sc2.alpha_normal:\n",
    "            structure_list_normal.append((torch.argmax(a, 1).cpu().detach().numpy()).tolist())    \n",
    "        with open('../../searchs/fmnist_darts_hypernet/genotype_{}_{}.json'.format(s, lam_), 'w') as out:\n",
    "            out.write(json.dumps([structure_list_reduce, structure_list_normal]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12496.)\n",
      "tensor(12352.)\n",
      "tensor(13120.)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "cfg['device'] = 'cuda'\n",
    "sc = SearchCNNControllerWithHyperNet(**cfg)    \n",
    "\n",
    "for s in seeds:        \n",
    "    sc2 = SearchCNNController(**cfg)\n",
    "    sc2.load_state_dict(torch.load('../../searchs/fmnist_darts/best_{}.pth.tar'.format(s)))\n",
    "    \n",
    "    fix_structure(sc2)\n",
    "    print (calc_param_number(sc2))\n",
    "    structure_list_reduce = []\n",
    "    structure_list_normal = []\n",
    "    for a in sc2.alpha_reduce:\n",
    "        structure_list_reduce.append((torch.argmax(a, 1).cpu().detach().numpy()).tolist())\n",
    "    for a in sc2.alpha_normal:\n",
    "        structure_list_normal.append((torch.argmax(a, 1).cpu().detach().numpy()).tolist())    \n",
    "    with open('../../searchs/fmnist_darts/genotype_{}.json'.format(s), 'w') as out:\n",
    "        out.write(json.dumps([structure_list_reduce, structure_list_normal]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:11<00:00, 41.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: 1e-08\n",
      "tensor(0.1803, device='cuda:0')\n",
      "param num tensor(5136., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:10<00:00, 42.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 13, lam: 1e-08\n",
      "tensor(0.1537, device='cuda:0')\n",
      "param num tensor(5392., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:11<00:00, 42.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 21, lam: 1e-08\n",
      "tensor(0.1014, device='cuda:0')\n",
      "param num tensor(4992., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:11<00:00, 42.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: 1e-07\n",
      "tensor(0.1876, device='cuda:0')\n",
      "param num tensor(5136., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:10<00:00, 42.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 13, lam: 1e-07\n",
      "tensor(0.1359, device='cuda:0')\n",
      "param num tensor(4080., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:11<00:00, 42.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 21, lam: 1e-07\n",
      "tensor(0.1013, device='cuda:0')\n",
      "param num tensor(5248., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:10<00:00, 42.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: 1e-06\n",
      "tensor(0.1930, device='cuda:0')\n",
      "param num tensor(5136., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:10<00:00, 42.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 13, lam: 1e-06\n",
      "tensor(0.1351, device='cuda:0')\n",
      "param num tensor(4080., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:10<00:00, 42.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 21, lam: 1e-06\n",
      "tensor(0.1009, device='cuda:0')\n",
      "param num tensor(5248., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:10<00:00, 42.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: 1e-05\n",
      "tensor(0.2060, device='cuda:0')\n",
      "param num tensor(3824., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:11<00:00, 42.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 13, lam: 1e-05\n",
      "tensor(0.1343, device='cuda:0')\n",
      "param num tensor(4080., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:10<00:00, 42.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 21, lam: 1e-05\n",
      "tensor(0.1015, device='cuda:0')\n",
      "param num tensor(5248., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:11<00:00, 42.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: 0.0001\n",
      "tensor(0.2083, device='cuda:0')\n",
      "param num tensor(3824., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:10<00:00, 43.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 13, lam: 0.0001\n",
      "tensor(0.1325, device='cuda:0')\n",
      "param num tensor(4080., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:10<00:00, 42.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 21, lam: 0.0001\n",
      "tensor(0.1012, device='cuda:0')\n",
      "param num tensor(5248., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# смотрим качество модели и количество параметров модели, которое мы получили на обучении (но с фиксацией структуры!)\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "cfg['device'] = 'cuda'\n",
    "for lam_ in range(-8, -3):\n",
    "    lam_ = 10.0**(lam_)\n",
    "    lam = torch.tensor([lam_])\n",
    "    for s in seeds:\n",
    "       \n",
    "        sc0 = SearchCNNControllerWithHyperNet(**cfg)        \n",
    "        sc0.load_state_dict(torch.load(ckp_path.format(s)))     \n",
    "        \n",
    "        sc = SearchCNNController(**cfg)\n",
    "        sc.net.load_state_dict(sc0.net.state_dict(), strict=False)     \n",
    "        sc.net.linear.weight.data = sc0.net.linear.weight.data * sc0.norm_lam(lam) + sc0.net.linear2.weight.data * (1.0-sc0.norm_lam(lam)) \n",
    "        sc.net.linear.bias.data = sc0.net.linear.bias.data * sc0.norm_lam(lam) + sc0.net.linear2.bias.data * (1.0-sc0.norm_lam(lam)) \n",
    "        \n",
    "        for h,a in zip(sc0.hyper_reduce, sc.alpha_reduce):\n",
    "            a.data = torch.clone((h(sc0.norm_lam(lam)) ))        \n",
    "        sc = sc.to('cuda')        \n",
    "        fix_structure(sc)\n",
    "        sc.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for x,y in tqdm.tqdm(valid_loader):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            out = sc(x)\n",
    "            correct += torch.eq(torch.argmax(out, 1), y).sum()\n",
    "            total += len(x)\n",
    "        \n",
    "        penalty = calc_param_number(sc)        \n",
    "        print ('seed {}, lam: {}'.format(s, lam_))\n",
    "        print (correct*1.0/total*1.0)\n",
    "        print ('param num', penalty)\n",
    "        print ('\\n'*3)\n",
    "                            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.4043188: : 469it [02:12,  3.55it/s] \n",
      "0.6799999999999999;0.39249295: : 469it [02:12,  3.53it/s]\n",
      "0.52;0.41450283: : 469it [02:12,  3.53it/s]              \n",
      "0.35999999999999993;0.47854024: : 469it [02:13,  3.52it/s]\n",
      "0.2;0.5066623: : 469it [02:13,  3.52it/s]                 \n",
      "100%|██████████| 469/469 [00:11<00:00, 42.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: 1e-08\n",
      "tensor(0.8107, device='cuda:0')\n",
      "param num tensor(5536., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.40814236: : 469it [02:14,  3.48it/s]\n",
      "0.6799999999999999;0.41312867: : 469it [02:13,  3.51it/s]\n",
      "0.52;0.47623208: : 469it [02:13,  3.51it/s]              \n",
      "0.35999999999999993;0.53664: : 469it [02:13,  3.50it/s]   \n",
      "0.2;0.53781337: : 469it [02:13,  3.51it/s]                \n",
      "100%|██████████| 469/469 [00:11<00:00, 42.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 13, lam: 1e-08\n",
      "tensor(0.7943, device='cuda:0')\n",
      "param num tensor(4624., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.412834: : 469it [02:14,  3.49it/s]  \n",
      "0.6799999999999999;0.39535308: : 469it [02:13,  3.50it/s]\n",
      "0.52;0.4488344: : 469it [02:13,  3.51it/s]               \n",
      "0.35999999999999993;0.5712375: : 469it [02:14,  3.50it/s] \n",
      "0.2;0.57487947: : 469it [02:14,  3.50it/s]                \n",
      "100%|██████████| 469/469 [00:11<00:00, 42.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 21, lam: 1e-08\n",
      "tensor(0.7800, device='cuda:0')\n",
      "param num tensor(2368., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.4046444: : 469it [02:14,  3.50it/s] \n",
      "0.6799999999999999;0.39429826: : 469it [02:14,  3.50it/s]\n",
      "0.52;0.435625: : 469it [02:14,  3.49it/s]                \n",
      "0.35999999999999993;0.49148074: : 469it [02:14,  3.49it/s]\n",
      "0.2;0.48702675: : 469it [02:14,  3.49it/s]                \n",
      "100%|██████████| 469/469 [00:11<00:00, 41.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: 1e-07\n",
      "tensor(0.8186, device='cuda:0')\n",
      "param num tensor(5536., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.4104831: : 469it [02:15,  3.47it/s] \n",
      "0.6799999999999999;0.4086935: : 469it [02:14,  3.49it/s] \n",
      "0.52;0.4882927: : 469it [02:14,  3.49it/s]               \n",
      "0.35999999999999993;0.5656745: : 469it [02:14,  3.49it/s] \n",
      "0.2;0.57952523: : 469it [02:14,  3.49it/s]                \n",
      "100%|██████████| 469/469 [00:11<00:00, 42.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 13, lam: 1e-07\n",
      "tensor(0.7696, device='cuda:0')\n",
      "param num tensor(2768., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.40220574: : 469it [02:15,  3.46it/s]\n",
      "0.6799999999999999;0.39326245: : 469it [02:14,  3.50it/s]\n",
      "0.52;0.4555588: : 469it [02:14,  3.49it/s]               \n",
      "0.35999999999999993;0.52977747: : 469it [02:14,  3.49it/s]\n",
      "0.2;0.56830007: : 469it [02:14,  3.49it/s]                \n",
      "100%|██████████| 469/469 [00:11<00:00, 42.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 21, lam: 1e-07\n",
      "tensor(0.7992, device='cuda:0')\n",
      "param num tensor(3280., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.40011162: : 469it [02:14,  3.48it/s]\n",
      "0.6799999999999999;0.3999156: : 469it [02:14,  3.50it/s] \n",
      "0.52;0.45893353: : 469it [02:14,  3.49it/s]              \n",
      "0.35999999999999993;0.4908115: : 469it [02:14,  3.49it/s] \n",
      "0.2;0.4823559: : 469it [02:14,  3.50it/s]                 \n",
      "100%|██████████| 469/469 [00:11<00:00, 42.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: 1e-06\n",
      "tensor(0.8139, device='cuda:0')\n",
      "param num tensor(5536., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.40802523: : 469it [02:13,  3.51it/s]\n",
      "0.6799999999999999;0.4077734: : 469it [02:13,  3.50it/s] \n",
      "0.52;0.49071798: : 469it [02:14,  3.49it/s]              \n",
      "0.35999999999999993;0.53119177: : 469it [02:14,  3.49it/s]\n",
      "0.2;0.5189696: : 469it [02:14,  3.49it/s]                 \n",
      "100%|██████████| 469/469 [00:11<00:00, 41.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 13, lam: 1e-06\n",
      "tensor(0.8030, device='cuda:0')\n",
      "param num tensor(5024., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.4033742: : 469it [02:15,  3.47it/s] \n",
      "0.6799999999999999;0.4110306: : 469it [02:14,  3.50it/s] \n",
      "0.52;0.5326376: : 469it [02:14,  3.50it/s]               \n",
      "0.35999999999999993;0.63631976: : 469it [02:14,  3.48it/s]\n",
      "0.2;0.64182293: : 469it [02:14,  3.50it/s]                \n",
      "100%|██████████| 469/469 [00:11<00:00, 42.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 21, lam: 1e-06\n",
      "tensor(0.7621, device='cuda:0')\n",
      "param num tensor(1712., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.39981738: : 469it [02:15,  3.46it/s]\n",
      "0.6799999999999999;0.41133812: : 469it [02:13,  3.50it/s]\n",
      "0.52;0.4694031: : 469it [02:14,  3.49it/s]               \n",
      "0.35999999999999993;0.49344125: : 469it [02:14,  3.49it/s]\n",
      "0.2;0.49546286: : 469it [02:14,  3.49it/s]                \n",
      "100%|██████████| 469/469 [00:11<00:00, 42.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: 1e-05\n",
      "tensor(0.8205, device='cuda:0')\n",
      "param num tensor(5136., device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.8400000000000001;0.40587115: : 469it [02:13,  3.51it/s]\n",
      "0.6799999999999999;0.43235728: : 469it [02:14,  3.50it/s]\n",
      "0.5851599147121536;0.50316465: : 278it [01:19,  3.52it/s]"
     ]
    }
   ],
   "source": [
    "# попробуем дообучить модельки с GS при фиксированной лямбде\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "cfg['device'] = 'cuda'\n",
    "for lam_ in range(-8, -3):\n",
    "    lam_ = 10.0**(lam_)\n",
    "    lam = torch.tensor([[lam_]]).cuda()\n",
    "    for s in seeds:\n",
    "       \n",
    "        sc0 = SearchCNNControllerWithHyperNet(**cfg)        \n",
    "        sc0.load_state_dict(torch.load(ckp_path.format(s)))     \n",
    "        sc0 = sc0.to('cuda')\n",
    "        sc0.samling_mode='gumbel-softmax'\n",
    "        \n",
    "        \n",
    "        batch_id = 0\n",
    "        for e in range(fine_epochs//2):\n",
    "            tq = tqdm.tqdm((zip(train_loader, valid_loader)))\n",
    "            losses = []\n",
    "            for ((trn_X, trn_y), (val_X, val_y)) in tq:\n",
    "                batch_id += 1                \n",
    "                t = 0.2 + (0.8 - 0.8 * batch_id/(fine_epochs//2*len(train_loader)))\n",
    "                sc0.t = t\n",
    "                trn_X, trn_y = trn_X.to('cuda', non_blocking=True), trn_y.to('cuda', non_blocking=True)\n",
    "                val_X, val_y = val_X.to('cuda', non_blocking=True), val_y.to('cuda', non_blocking=True)        \n",
    "                loss = sc0.train_step(trn_X, trn_y, val_X, val_y, lam).detach().cpu().numpy()\n",
    "                losses.append(loss)\n",
    "                tq.set_description('{};{}'.format(sc0.t, str(np.mean(losses))))\n",
    "                \n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "        sc = SearchCNNController(**cfg).to('cuda')\n",
    "        sc.net.load_state_dict({k:v for k,v in sc0.net.state_dict().items() if not k.startswith('linear')}, strict=False)     \n",
    "        sc.net.linear.weight.data = sc0.net.linear.weight.data * sc0.norm_lam(lam.cuda()) + sc0.net.linear2.weight.data * (1.0-sc0.norm_lam(lam.cuda())) \n",
    "        sc.net.linear.bias.data = sc0.net.linear.bias.data * sc0.norm_lam(lam.cuda()) + sc0.net.linear2.bias.data * (1.0-sc0.norm_lam(lam.cuda())) \n",
    "        \n",
    "        for h,a in zip(sc0.hyper_reduce, sc.alpha_reduce):\n",
    "            a.data = torch.clone((h(sc0.norm_lam(lam.cuda())) ))        \n",
    "        sc = sc.to('cuda')        \n",
    "        fix_structure(sc)\n",
    "        sc.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for x,y in tqdm.tqdm(valid_loader):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            out = sc(x)\n",
    "            correct += torch.eq(torch.argmax(out, 1), y).sum()\n",
    "            total += len(x)\n",
    "        \n",
    "        penalty = calc_param_number(sc)        \n",
    "        print ('seed {}, lam: {}'.format(s, lam_))\n",
    "        print (correct*1.0/total*1.0)\n",
    "        print ('param num', penalty)\n",
    "        print ('\\n'*3)\n",
    "        torch.save(sc0.state_dict(), 'model_{}_prefine_lam_{}.pth'.format(s, lam_ ))\n",
    "                            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['linear.weight', 'linear.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.net.load_state_dict({k:v for k,v in sc0.net.state_dict().items() if not k.startswith('linear')}, strict=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc0.load_state_dict(torch.load('model_{}_prefine_lam_{}.pth'.format(21, 1e-05)))\n",
    "\n",
    "#sc0.load_state_dict(torch.load(ckp_path.format(21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['linear.weight', 'linear.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.net.load_state_dict({k:v for k,v in sc0.net.state_dict().items() if not k.startswith('linear')}, strict=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4192"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4192*1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.6793, -0.8374,  0.0809, -0.2418,  0.5758,  0.0916, -0.6825,  2.2758],\n",
      "        [-0.6861, -0.7966, -0.4870, -0.3345, -0.2127,  0.4595,  0.5867,  1.7800]],\n",
      "       device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[-0.7620, -0.2313, -0.5894,  0.2517, -0.6279,  0.4361, -0.3550,  2.0233],\n",
      "        [-0.5545, -0.2676, -0.4321,  0.0770, -0.4739,  0.1332, -0.2282,  2.0525],\n",
      "        [ 0.6882, -0.0700,  0.4858,  0.0176, -0.0161, -0.2411, -0.0498,  1.1780]],\n",
      "       device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[-0.3577,  0.4244, -0.5864, -0.4812,  0.4161, -0.5056, -0.6018,  1.4522],\n",
      "        [-0.4509, -0.2380,  0.6548, -0.4999, -0.3036, -0.1844, -0.4880,  1.4063],\n",
      "        [-0.2787, -0.1226,  0.3400, -0.6762,  0.6923, -0.2661, -0.5475,  1.1888],\n",
      "        [-0.2631, -0.1943,  0.1652,  0.0118,  0.0536,  0.3022, -0.7372,  1.1762]],\n",
      "       device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[ 0.1350,  0.3346, -0.1099, -0.4033, -0.7179, -0.1483, -0.4896,  1.4195],\n",
      "        [-0.1266, -0.0634, -0.1701, -0.2667, -0.8037, -0.1739, -0.5100,  2.0735],\n",
      "        [ 0.0370,  0.0318,  0.3807, -0.6505,  0.3583, -0.1603, -0.4814,  0.6394],\n",
      "        [ 0.3380,  0.3103,  0.3595, -0.1400, -0.4937, -0.3019, -0.4685,  0.4377],\n",
      "        [ 0.7599,  0.5380, -0.3906, -0.3388,  0.3599,  0.0681, -0.1702, -0.6232]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for a in sc.alpha_reduce:\n",
    "    print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.2752, -1.1633, -0.0377,  0.1065,  0.7666, -0.2744, -1.3294,  2.5319],\n",
      "        [-1.5961, -1.8689, -1.5031, -0.8603, -0.8925, -0.4113,  1.9811,  0.3283]],\n",
      "       device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[-0.8614, -0.6020, -0.7579, -0.7302, -0.4433,  0.2239, -0.6985,  2.8633],\n",
      "        [-1.0295, -1.1201, -0.5128, -0.3750, -0.7249,  0.1413,  0.1304,  2.8212],\n",
      "        [ 1.6851,  0.0339, -0.2289, -0.5038,  0.0593, -0.9414, -0.6293, -0.3387]],\n",
      "       device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[-0.2573,  0.3016, -1.4422, -0.4495,  1.7029, -1.4176, -1.6134, -0.3078],\n",
      "        [-1.0416, -1.0655,  0.8919, -0.0287, -0.5155, -0.6061, -0.5152,  2.1735],\n",
      "        [-0.9524, -0.7642, -0.4555, -0.9560,  2.0914, -1.2969, -1.5526,  0.4531],\n",
      "        [-0.7527, -0.7405, -0.2592,  0.4203, -0.6379,  0.3502, -1.2180,  2.3595]],\n",
      "       device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[-0.1654, -0.6048, -0.7071, -0.1080, -1.0438, -0.3818,  0.0310,  2.1932],\n",
      "        [-1.1209, -1.1527, -0.3230, -0.6139, -1.3468,  0.6893, -0.5001,  2.8857],\n",
      "        [-0.0084, -0.1700,  0.7057,  0.3434, -0.5284,  0.2919, -1.1777,  2.0296],\n",
      "        [-0.5175, -0.6558, -0.1037, -0.5919, -1.0356, -0.5991, -1.0017,  2.2799],\n",
      "        [-0.6146, -0.8305, -1.3311, -0.8174,  2.0414, -0.8767, -1.1577, -0.9832]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for a in sc.alpha_reduce:\n",
    "    print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0., -0., 0., -0., 0., 0., -0., 1.],\n",
      "        [-0., -0., -0., -0., -0., 0., 0., 1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[-0., -0., -0., 0., -0., 0., -0., 1.],\n",
      "        [-0., -0., -0., 0., -0., 0., -0., 1.],\n",
      "        [0., -0., 0., 0., -0., -0., -0., 1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[-0., 0., -0., -0., 0., -0., -0., 1.],\n",
      "        [-0., -0., 0., -0., -0., -0., -0., 1.],\n",
      "        [-0., -0., 0., -0., 0., -0., -0., 1.],\n",
      "        [-0., -0., 0., -0., 0., 0., -0., 1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[0., 0., -0., -0., -0., -0., -0., 1.],\n",
      "        [-0., -0., -0., -0., -0., -0., -0., 1.],\n",
      "        [0., 0., 0., -0., 0., -0., -0., 1.],\n",
      "        [0., 0., 0., -0., -0., -0., -0., 1.],\n",
      "        [1., 0., -0., -0., 0., 0., -0., -0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "lam_ = 1.0\n",
    "for h,a in zip(sc0.hyper_reduce, sc.alpha_reduce):\n",
    "                a.data = torch.clone(h(torch.tensor([lam_]).cuda()) )\n",
    "       \n",
    "fix_structure(sc)\n",
    "for a in sc.alpha_reduce:\n",
    "    print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def hyperloss(self, X, y, lam):\n",
    "        #logits = self.forward(X, lam)\n",
    "        penalty = 0\n",
    "        \n",
    "        for id, cell in enumerate(self.net.cells):\n",
    "            # можно не пробегать несколько раз, т.к. клетки одинаковы (С точностью до normal и reduce)            \n",
    "            \n",
    "            lam_ = self.norm_lam(lam)\n",
    "            weights = [alpha(lam_) for alpha in self.hyper_reduce] if cell.reduction else [\n",
    "                alpha(lam_) for alpha in self.hyper_normal]\n",
    "            \n",
    "            weights = [F.softmax(w/self.t, dim=-1) for w in weights]\n",
    "            \n",
    "              \n",
    "            for edges, w_list in zip(cell.dag, weights):\n",
    "                for mixed_op, weights in zip(edges, w_list):\n",
    "                    for op, w in zip(mixed_op._ops, weights):                        \n",
    "                        for param in op.parameters():\n",
    "                            penalty += w*np.prod(param.shape)          \n",
    "            #penalty += lam_[0,0] * (torch.norm(self.net.linear.weight)**2 + torch.norm(self.net.linear.bias)**2)\n",
    "            #penalty += (1.0-lam_[0,0]) * (torch.norm(self.net.linear2.weight)**2 + torch.norm(self.net.linear2.bias)**2)\n",
    "            \n",
    "\n",
    "        # oleg return self.criterion(logits, y)   + penalty * lam[0,0] \n",
    "        return penalty \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc0 = sc0.cuda()\n",
    "sc0.t = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6328.6978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5707.0322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5262.7612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4670.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3872.0901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3365.1294, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for r in range(-10, -4):\n",
    "    \n",
    "    print (hyperloss(sc0, 0, 0, torch.tensor([[10**r]]).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'64'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 1.1084],\n",
       "         [-0.0756],\n",
       "         [-0.0762],\n",
       "         [-0.0475],\n",
       "         [-0.6884],\n",
       "         [-0.0391],\n",
       "         [-0.0297],\n",
       "         [-0.0831],\n",
       "         [ 1.0998],\n",
       "         [-0.0604],\n",
       "         [-0.0712],\n",
       "         [-0.0253],\n",
       "         [-0.6183],\n",
       "         [-0.0505],\n",
       "         [-0.0459],\n",
       "         [-0.0997]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 1.5646, -0.8272, -0.6284, -0.3190,  1.9144, -0.6870, -0.3635, -1.1838,\n",
       "          1.3121, -0.8585, -0.7832,  0.6159,  1.7367, -0.8624, -0.6465, -1.3189],\n",
       "        device='cuda:0', requires_grad=True))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc0.hyper_reduce[0].model[0].weight, sc0.hyper_reduce[0].model[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: -4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "  3%|▎         | 27/938 [00:02<01:27, 10.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-dc656a98e3d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/bakhteev/var_nas/models/cnn/search_cnn.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/bakhteev/var_nas/models/cnn/search_cnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bad sampling mode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/bakhteev/var_nas/models/cnn/search_cnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, weights_normal, weights_reduce)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_reduce\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mweights_normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/bakhteev/var_nas/models/cnn/search_cells.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, s0, s1, w_dag)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mw_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0ms_cur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_cur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/bakhteev/var_nas/models/cnn/search_cells.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mw_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0ms_cur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_cur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lam_ in [-4.0,  -1.0]:\n",
    "        lam = torch.tensor([10**lam_])\n",
    "        # создаем модель с обязательным указанием, что к структуре не применяется softmax\n",
    "        cfg = ConfigObj(basecfg_path)\n",
    "        cfg['darts']['sampling_mode'] = 'naive' \n",
    "        cfg['device'] = 'cuda'    \n",
    "        for s in seeds:\n",
    "            print (s)\n",
    "            sc0 = SearchCNNControllerWithHyperNet(**cfg)        \n",
    "            sc0.load_state_dict(torch.load(ckp_path.format(s)))                            \n",
    "            sc = SearchCNNController(**cfg)\n",
    "            \n",
    "            sc.net.load_state_dict(sc0.net.state_dict())\n",
    "            for h,a in zip(sc0.hyper_reduce, sc.alpha_reduce):\n",
    "                a.data = torch.clone(h(lam))                                            \n",
    "            fix_structure(sc)\n",
    "            \n",
    "            sc = sc.to('cuda')\n",
    "            optim = torch.optim.Adam(sc.weights())\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # дообучаем n эпох\n",
    "            print ('seed {}, lam: {}'.format(s, lam_))\n",
    "            for e in range(5):\n",
    "                for x,y in tqdm.tqdm(train_loader):\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()            \n",
    "                    optim.zero_grad()\n",
    "                    loss = sc.loss(x,y)\n",
    "                    loss.backward()\n",
    "                    optim.step()                              \n",
    "                \n",
    "                sc.eval()\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for x,y in tqdm.tqdm(valid_loader):\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()\n",
    "                    out = sc(x)\n",
    "                    correct += torch.eq(torch.argmax(out, 1), y).sum()\n",
    "                    total += len(x)\n",
    "                print (correct*1.0/total*1.0)\n",
    "                sc.train()\n",
    "            torch.save(sc.state_dict(), ckp_path.format(s)+'{}.fine'.format(lam_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 21, lam: -4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.77it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0960, device='cuda:0')\n",
      "seed 21, lam: -1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0967, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# смотрим качество модели, которое мы получили на обучении\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "cfg['device'] = 'cuda'\n",
    "for lam_ in [-4.0,  -1.0]:\n",
    "    for s in seeds:\n",
    "        print ('seed {}, lam: {}'.format(s, lam_))\n",
    "        sc = SearchCNNController(**cfg)\n",
    "        \n",
    "        sc.load_state_dict(torch.load(ckp_path.format(s)+'{}.fine'.format(lam_)))\n",
    "        \n",
    "        sc = sc.to('cuda')\n",
    "        sc.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for x,y in tqdm.tqdm(valid_loader):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            out = sc(x)\n",
    "            correct += torch.eq(torch.argmax(out, 1), y).sum()\n",
    "            total += len(x)\n",
    "        print (correct*1.0/total*1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterList(\n",
       "    (0): Parameter containing: [torch.FloatTensor of size 2x8]\n",
       "    (1): Parameter containing: [torch.FloatTensor of size 3x8]\n",
       "    (2): Parameter containing: [torch.FloatTensor of size 4x8]\n",
       "    (3): Parameter containing: [torch.FloatTensor of size 5x8]\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
