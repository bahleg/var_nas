{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnn.search_cnn import  SearchCNN, SearchCNNController\n",
    "from models.cnn_darts_hypernet.search_cnn_darts_hypernet_legacy import  SearchCNNControllerWithHyperNet\n",
    "\n",
    "from configobj import ConfigObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "# get data with meta info\n",
    "input_size, input_channels, n_classes, train_data, valid_data = utils.get_data(\n",
    "    'fashionmnist', '../../data/', cutout_length=0, validation=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                               batch_size=64,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=32,\n",
    "                                               pin_memory=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=1,\n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basecfg_path = '../../configs/hyper/fmnist_hyper.cfg'  #конфиг, на который мы ориентируемся при загрузки модели\n",
    "\n",
    "\n",
    "\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "name = cfg['name'] # имя для сохранения результатов\n",
    "ckp_path = 'checkpoint_0_49.ckp' # это шаблон названия сохраненных моделей\n",
    "seeds = ['0']  # сиды. можно брать из конфига\n",
    "\n",
    "\n",
    "fine_tune = True # надо ли дообучать модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_structure(sc): # во время тестов нашей модели нужно перейти от непрерывной структуры к one-hot\n",
    "    for alpha in sc.alpha_reduce:\n",
    "        alpha.requires_grad = False\n",
    "        for subalpha in alpha:\n",
    "            \n",
    "            argm = torch.argmax(subalpha)\n",
    "            subalpha.data*=0\n",
    "            subalpha.data[argm] += 1\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg['model_class'] = 'models.cnn_darts_hypernet.search_cnn_darts_hypernet_legacy.SearchCNNControllerWithHyperNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=64, out_features=10, bias=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.net.linear2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.26it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8205, device='cuda:0')\n",
      "seed 0, lam: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7510, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# смотрим качество модели, которое мы получили на обучении, без фиксации структуры\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "cfg['device'] = 'cuda'\n",
    "for lam_ in [0.0, 1.0]:\n",
    "    lam = torch.tensor([lam_]).to('cuda')\n",
    "    for s in seeds:\n",
    "        print ('seed {}, lam: {}'.format(s, lam_))\n",
    "        sc = SearchCNNControllerWithHyperNet(**cfg)\n",
    "        \n",
    "        sc.load_state_dict(torch.load(ckp_path.format(s)))\n",
    "        \n",
    "        sc = sc.to('cuda')\n",
    "        sc.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for x,y in tqdm.tqdm(valid_loader):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            out = sc(x, lam)\n",
    "            correct += torch.eq(torch.argmax(out, 1), y).sum()\n",
    "            total += len(x)\n",
    "        print (correct*1.0/total*1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2896edae0680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "out = (sc(x, 0.0*torch.ones(1,1).cuda()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dfa6bbb3eb7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "torch.eq(torch.argmax(out, 1), y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: 0.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SearchCNNControllerWithHyperNet' object has no attribute 'norm_lam'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3e1e516231a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper_reduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_lam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mfix_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 948\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SearchCNNControllerWithHyperNet' object has no attribute 'norm_lam'"
     ]
    }
   ],
   "source": [
    "# смотрим качество модели, которое мы получили на обучении, без фиксации структуры, но с переводом на обычный DARTS\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "cfg['device'] = 'cuda'\n",
    "for lam_ in [0.0, 1.0]:\n",
    "    lam = torch.tensor([lam_])\n",
    "    for s in seeds:\n",
    "        print ('seed {}, lam: {}'.format(s, lam_))\n",
    "        sc0 = SearchCNNControllerWithHyperNet(**cfg)        \n",
    "        sc0.load_state_dict(torch.load(ckp_path.format(s)))     \n",
    "        \n",
    "        sc = SearchCNNController(**cfg)\n",
    "\n",
    "        sc.net = sc0.net\n",
    "        for h,a in zip(sc0.hyper_reduce, sc.alpha_reduce):\n",
    "            a.data = torch.clone(sc0.norm_lam(h(lam)) )\n",
    "        fix_structure(sc)\n",
    "        sc = sc.to('cuda')\n",
    "        sc.sampling_mode='naive'\n",
    "        sc.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for x,y in tqdm.tqdm(valid_loader):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            out = sc(x)\n",
    "            correct += torch.eq(torch.argmax(out, 1), y).sum()\n",
    "            total += len(x)\n",
    "        print (correct*1.0/total*1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfigObj({'dataset': 'mnist', 'model_class': 'models.cnn_darts_hypernet.search_cnn_darts_hypernet.SearchCNNControllerWithHyperNet', 'name': 'mnist_darts_hypernet_gs', 'batch_size': '64', 'epochs': '50', 'validate_split': '0.5', 'quality': 'top1', 'use_train_quality': '0', 'seeds': '0', 'device': 'cuda', 'darts': {'layers': '1', 'init_channels': '8', 'input_channels': '1', 'n_classes': '10', 'n_nodes': '1', 'stem_multiplier': '3', 'sampling_mode': 'gumbel-softmax', 'initial temp': '1.0', 'delta': '-0.016', 'primitives': 'DARTS', 'optim': {'simple_alpha_update': '1', 'alpha_lr': '0.001', 'w_lr': '0.025', 'w_lr_min': '0.001', 'w_momentum': '0.9', 'w_weight_decay': '0.0', 'w_grad_clip': '5.0', 'alpha_weight_decay': '0.001'}}, 'hypernetwork': {'hidden_layer_num': '0', 'hidden_layer_size': '0', 'log10_lambda_min': '-8', 'log10_lambda_max': '-1', 'lambda sample num': '3'}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6bc0045ec17e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sc0' is not defined"
     ]
    }
   ],
   "source": [
    "sc0.t = 0.2\n",
    "sc0 = sc0.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2452e+00, -4.1482e-01, -9.1407e-01, -9.3603e-01,  4.8313e-01,\n",
       "          1.2585e+00,  3.9381e+00, -1.2690e+00, -2.0555e+00, -2.2790e+00],\n",
       "        [-9.5342e-01,  1.5255e+00, -1.3422e-02, -4.6181e-01,  6.5338e-01,\n",
       "          1.5822e-01, -6.2305e-02,  1.6915e+00, -2.1149e+00, -7.6552e-01],\n",
       "        [-8.4605e-01, -1.7980e+00,  1.7671e+00,  1.1048e+00, -6.6364e-01,\n",
       "          1.0337e+00, -6.7482e-01, -1.0612e+00,  1.4877e+00, -2.2239e-01],\n",
       "        [-2.4437e+00, -2.2934e+00, -1.3324e+00,  8.8219e-01,  1.3497e+00,\n",
       "          1.4288e+00, -1.4729e+00,  2.6151e+00, -4.8652e-01,  1.1727e+00],\n",
       "        [ 3.1879e-02, -1.0538e+00,  7.7814e-01, -1.5051e-01, -3.1145e-01,\n",
       "          1.9647e+00,  5.5327e-01, -1.9894e-01, -2.8079e-01, -1.6805e+00],\n",
       "        [ 3.9937e+00,  7.6366e+00, -4.8666e+00, -6.4957e+00,  1.0835e+00,\n",
       "         -6.5719e-01,  4.8326e+00,  6.0533e-01, -3.4464e+00, -3.2394e-01],\n",
       "        [-1.6168e+00,  7.7880e-01,  1.9563e+00,  1.8378e+00, -4.6235e-01,\n",
       "          6.9982e-01, -1.5174e+00,  9.7083e-01, -1.2203e+00, -1.2296e+00],\n",
       "        [-3.8184e+00, -1.3988e+00,  2.8349e+00,  4.9690e+00, -8.2680e-01,\n",
       "          2.9075e+00, -4.7602e+00,  2.6924e+00, -1.4315e+00, -2.3620e+00],\n",
       "        [-2.2268e+00,  1.6818e+00, -4.3514e+00, -2.0096e+00,  7.9320e+00,\n",
       "          8.2601e-01, -9.0227e-01, -1.9902e-01,  2.1375e-01, -7.2096e-01],\n",
       "        [ 1.2644e+00,  1.5791e+00, -1.6602e+00,  6.7420e-01, -2.2379e+00,\n",
       "          2.0089e+00, -6.9696e-01,  2.6632e+00, -2.9017e+00, -6.7243e-01],\n",
       "        [-6.9566e-01, -2.6636e+00,  8.8010e-01,  3.3055e-01,  2.6928e+00,\n",
       "         -8.7789e-01, -3.5612e-01, -2.3240e+00,  1.8848e+00,  3.2761e-01],\n",
       "        [-6.6085e-02, -2.7168e+00, -1.6951e+00, -1.8163e+00,  2.5157e+00,\n",
       "         -1.7379e-01, -1.1050e+00,  2.3260e+00, -5.0952e-01,  2.3564e+00],\n",
       "        [ 2.0263e+00,  2.4727e+00, -1.1974e+00, -1.8571e+00, -2.9767e-01,\n",
       "         -5.0950e-01,  1.1340e+00,  7.7235e-01, -1.5618e+00, -2.6058e-01],\n",
       "        [ 1.0385e+00, -1.0680e+00, -1.0326e+00, -1.1889e+00,  1.8086e+00,\n",
       "         -1.3158e+00,  7.1971e-01,  1.3393e+00, -1.1077e+00,  2.7159e-01],\n",
       "        [-2.8537e-01,  3.0551e-01, -8.7352e-01,  1.0874e-01, -1.0586e+00,\n",
       "          2.6478e+00,  1.1814e+00, -1.8885e+00,  1.1622e+00, -9.3137e-01],\n",
       "        [-3.2222e-01, -8.7192e-01,  6.9400e-01,  1.2607e+00, -6.3454e-01,\n",
       "          1.3485e+00, -1.7907e+00,  1.8722e+00, -1.1203e+00, -7.4676e-01],\n",
       "        [-2.7929e+00, -5.6849e+00,  2.7628e+00,  5.5311e+00, -1.5588e+00,\n",
       "          1.7681e+00, -2.3881e+00, -1.8237e+00,  2.9763e+00, -6.1353e-01],\n",
       "        [-2.2335e+00, -6.4857e-01,  8.0102e-01,  1.8526e+00,  1.1799e-01,\n",
       "          6.6759e-01, -1.2009e+00,  1.5635e+00, -5.8125e-01, -7.4217e-01],\n",
       "        [ 5.3100e-01, -5.2770e+00,  2.8082e-01, -7.0798e-01, -7.1943e-01,\n",
       "         -2.1446e+00, -8.5960e-01,  1.3444e+00,  2.2863e+00,  5.0896e+00],\n",
       "        [ 2.5049e-01, -2.1185e+00,  1.2563e+00, -1.5485e+00, -1.6667e+00,\n",
       "          2.3162e+00,  2.5091e+00, -2.6404e+00,  3.1610e+00, -8.8228e-01],\n",
       "        [ 1.3406e+00, -2.9694e+00, -4.2385e-01,  7.7173e-01, -2.7468e-01,\n",
       "          4.4642e-01,  5.3683e-01, -2.5198e-01,  1.8079e-01, -1.2940e-01],\n",
       "        [-3.6468e+00, -1.5653e+00, -3.0175e-01,  3.7086e+00,  1.4176e+00,\n",
       "          3.5460e+00, -2.1679e+00,  1.8119e-01, -4.2231e-01, -2.0332e+00],\n",
       "        [-1.0763e+00, -2.1573e+00,  1.7888e+00,  1.0712e-01, -1.4818e+00,\n",
       "          2.6222e+00,  1.5885e+00, -1.9283e+00,  1.8157e+00, -8.4527e-01],\n",
       "        [-1.5064e-01, -3.5956e-01,  6.4670e-01,  7.7184e-01,  2.7228e-01,\n",
       "         -5.2364e-01, -2.5790e-01, -1.0037e-01,  9.5240e-02, -5.4957e-01],\n",
       "        [ 7.1558e-01, -1.1644e+00,  4.0704e-01, -8.8339e-02, -2.2502e-02,\n",
       "         -5.6851e-01,  8.3726e-01, -5.9037e-01,  5.0049e-01, -9.0588e-03],\n",
       "        [ 2.1697e+00,  3.6834e+00, -4.1367e+00, -4.5068e+00,  1.8329e+00,\n",
       "          2.7736e+00,  5.5684e+00, -1.5045e+00, -2.1417e+00, -2.5236e+00],\n",
       "        [-1.7387e-01,  5.9323e-01, -7.4347e-01,  8.0078e-02,  7.3412e-02,\n",
       "          1.4063e+00, -2.7313e-01,  1.2246e+00, -1.4225e+00, -7.6034e-01],\n",
       "        [ 2.7015e-01, -8.1680e-01,  7.0492e-01,  1.7421e-01,  6.1055e-02,\n",
       "          1.0058e+00, -2.1795e-02, -1.7593e-01, -3.4577e-01, -9.4697e-01],\n",
       "        [ 3.6235e-01,  1.4973e+00,  2.6087e+00,  2.2588e+00, -3.9613e+00,\n",
       "          1.3891e-01, -2.7620e+00,  5.6388e+00, -5.6087e+00, -5.3978e-01],\n",
       "        [-7.8768e-01,  2.3776e+00, -1.1074e+00,  3.8378e-01, -6.2076e-01,\n",
       "         -9.3235e-01, -8.3277e-01,  3.8182e+00, -2.3788e+00,  9.7325e-01],\n",
       "        [ 1.5878e+00,  3.5386e+00, -2.1510e+00, -2.6282e+00,  1.9682e+00,\n",
       "         -8.3141e-01,  1.2253e+00,  2.5202e-01, -1.3660e+00, -2.4004e-01],\n",
       "        [-3.2497e-01, -8.9717e-01, -4.6911e-01, -4.4427e-01,  2.0130e+00,\n",
       "          1.5823e+00,  5.3167e-01, -1.3296e+00,  1.9703e-01, -1.0709e+00],\n",
       "        [ 1.0239e-01, -1.4063e+00, -6.8983e-01, -3.9481e-01,  1.3640e+00,\n",
       "         -3.4294e-01, -5.6341e-01,  1.9679e+00, -8.1303e-01,  7.4593e-01],\n",
       "        [ 2.9793e+00,  4.4609e+00, -2.5447e+00, -3.5705e+00,  6.5848e-01,\n",
       "         -2.0161e+00,  1.6796e+00,  2.0292e+00, -2.9149e+00,  6.8340e-01],\n",
       "        [-2.6436e+00, -4.3042e+00,  4.3471e+00,  6.1188e+00, -1.9454e-01,\n",
       "          3.3807e+00, -2.5121e+00, -1.1957e+00, -1.1834e+00, -4.6752e+00],\n",
       "        [ 1.7823e+00, -4.0292e-01, -2.0976e-01, -2.2151e+00,  9.1436e-01,\n",
       "          4.6476e-01,  2.6034e+00, -1.4721e+00, -7.4483e-01, -1.3953e+00],\n",
       "        [ 1.3937e-01, -3.7197e-01,  6.1754e-01,  2.4339e-01, -1.3917e-01,\n",
       "          9.7975e-01,  8.3111e-02,  4.1404e-01, -4.3393e-01, -1.8565e+00],\n",
       "        [-1.5754e+00, -1.5454e+00,  2.4913e+00,  2.3987e+00, -7.1530e-03,\n",
       "          1.3897e+00, -2.5207e+00,  1.2720e+00, -9.6269e-01, -2.0176e+00],\n",
       "        [-7.9247e-01, -3.5839e+00,  1.1974e-01,  3.5373e-01,  6.5267e-01,\n",
       "          8.3553e-01, -1.9602e-01, -2.2967e+00,  3.0804e+00,  1.0944e+00],\n",
       "        [-1.5684e+00, -2.0511e-01,  2.3350e+00,  1.0164e+00,  1.7701e-01,\n",
       "          5.2628e-01, -1.6636e+00,  1.1342e+00, -6.7604e-01, -9.4056e-01],\n",
       "        [-1.2012e+00, -2.2024e+00,  7.0835e-01,  2.3217e+00, -4.1009e-01,\n",
       "          1.7638e+00, -9.0590e-01,  2.5123e-02, -2.0385e-01, -1.0012e+00],\n",
       "        [ 8.3186e-01, -2.7674e+00,  5.2414e-01, -4.0837e-01,  2.5358e-01,\n",
       "         -6.2375e-01,  1.1033e+00, -2.0793e+00,  2.0895e+00,  6.1097e-01],\n",
       "        [-6.5709e-01, -1.0517e+00, -1.3498e+00,  7.4701e-01,  4.8038e-01,\n",
       "          1.4932e-01,  5.6989e-02,  1.1396e+00, -4.8820e-01,  6.8750e-01],\n",
       "        [ 1.5462e-01, -8.0386e-01, -1.4230e+00, -7.8248e-01,  5.3893e-01,\n",
       "          2.0889e+00,  1.7681e+00, -2.5583e+00,  1.8574e+00, -6.8105e-01],\n",
       "        [ 1.3234e+00, -7.1618e+00, -9.3992e-01,  8.6839e-01,  9.2702e-01,\n",
       "         -1.1742e-01,  1.0946e+00, -2.8859e+00,  4.8929e+00,  1.1926e+00],\n",
       "        [-1.1000e+00, -3.7911e+00,  6.8612e-01, -2.2358e-02,  3.6564e+00,\n",
       "         -2.8363e-01, -1.1482e-01, -1.4585e+00,  1.5616e+00, -6.3746e-01],\n",
       "        [-2.0453e+00,  8.0582e-01,  2.6964e-01,  1.0377e+00,  1.0185e+00,\n",
       "         -1.1384e-01, -1.3478e+00,  2.9252e+00, -1.9776e+00, -9.0728e-01],\n",
       "        [ 2.4383e+00,  3.6413e+00, -2.6535e+00, -2.0571e+00,  2.9015e-01,\n",
       "         -1.0618e+00,  2.1793e+00,  1.2819e+00, -2.8240e+00,  4.5845e-01],\n",
       "        [-1.7322e-01, -1.8092e-02, -1.0721e+00,  2.1562e+00, -1.2575e+00,\n",
       "          2.1903e+00, -1.8355e+00,  2.5935e+00, -2.3334e+00, -1.0884e+00],\n",
       "        [ 9.6993e-01,  1.4880e+00, -2.4561e+00, -5.4572e-01, -1.2397e+00,\n",
       "          2.2758e-01,  7.1330e-01,  1.1724e+00,  6.1106e-01,  1.2369e+00],\n",
       "        [ 3.4289e+00,  4.7581e+00, -3.2834e+00, -3.2806e+00, -2.3931e-01,\n",
       "         -7.8521e-01,  3.1654e+00,  7.4173e-01, -2.5185e+00, -4.1589e-01],\n",
       "        [ 1.5297e+00,  6.9740e-02, -3.1996e-01, -1.5811e+00,  1.3698e+00,\n",
       "         -9.8761e-01,  1.9441e-01,  1.8558e+00, -1.7210e+00, -7.8092e-01],\n",
       "        [-1.8143e+00, -1.4737e+00,  1.4299e+00,  2.4159e+00,  1.0999e+00,\n",
       "          3.3216e-01, -2.0555e+00,  6.6743e-01, -2.8870e-01, -1.1508e+00],\n",
       "        [ 1.2569e-01,  3.6025e-01, -2.3807e-01, -1.7586e+00,  3.0693e+00,\n",
       "         -6.7757e-01,  4.0609e-01,  1.0248e+00, -1.2779e+00, -8.6633e-01],\n",
       "        [-3.0169e+00,  1.5975e+00,  7.9234e-01,  1.8029e+00,  1.7509e+00,\n",
       "          1.2676e+00, -1.6234e+00,  8.4995e-01, -2.1046e+00, -1.3681e+00],\n",
       "        [-4.9720e-01, -3.9307e-01, -1.0407e-01,  6.9704e-02,  1.7938e-01,\n",
       "          1.3578e+00,  4.3718e-01, -1.5145e-02, -2.0256e-01, -8.3772e-01],\n",
       "        [ 7.5678e-01, -9.6097e-01, -1.1625e-01, -6.1770e-01,  3.2368e-01,\n",
       "         -3.1661e-01,  3.3493e-01,  1.0537e+00, -4.8689e-01, -4.2673e-02],\n",
       "        [-9.1494e-01,  2.0408e+00, -6.0298e-01,  5.6204e-01, -2.5523e-01,\n",
       "         -1.5498e-01, -1.7772e+00,  3.0087e+00, -2.2353e+00,  5.2671e-01],\n",
       "        [ 1.8439e-01, -4.9845e-01, -3.9004e-01, -2.7431e-01,  5.7849e-01,\n",
       "         -7.7444e-02, -1.1713e-01,  1.2876e+00, -1.3673e+00,  1.6665e-01],\n",
       "        [-2.6075e+00,  1.8113e+00,  1.8468e+00,  1.5221e+00, -2.2256e-01,\n",
       "          1.3004e+00, -1.5839e+00,  1.8401e+00, -1.6069e+00, -1.9782e+00],\n",
       "        [-8.2635e-01, -6.0645e-01,  5.8324e-01,  1.5844e+00, -1.0476e+00,\n",
       "          2.0524e+00, -3.4400e-01,  6.3954e-01, -9.3976e-01, -1.8293e+00],\n",
       "        [-8.3226e-01, -7.8525e-01, -8.6356e-01, -2.8769e-01,  2.5256e+00,\n",
       "         -3.9555e-01, -2.0169e-01,  6.0996e-01,  5.6885e-02,  1.8461e-01],\n",
       "        [-4.4738e-02, -1.8020e+00,  9.4328e-01,  9.0271e-01,  3.2675e-01,\n",
       "         -4.8971e-01,  3.0721e-01, -4.3988e-01,  4.3001e-01, -3.3787e-01],\n",
       "        [ 5.2621e-02, -6.3829e-01, -1.5090e+00, -1.6855e-01,  1.9419e+00,\n",
       "         -7.2770e-01, -5.6808e-01,  1.3777e+00, -1.3067e+00,  1.3347e+00]],\n",
       "       device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sc(x) - sc0(x, torch.tensor([10e-9]).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8079, -0.9030, -0.6230, -0.2134,  3.2586, -0.3532, -0.4448, -0.4817],\n",
       "         [-0.8494, -0.8544, -0.6758, -0.5583,  4.6323, -0.5762, -0.6024, -0.5743]],\n",
       "        grad_fn=<ViewBackward>),\n",
       " tensor([[-1.0875, -1.2262, -0.8786, -0.3082,  4.5715, -0.4987, -0.6206, -0.6553],\n",
       "         [-1.1367, -1.1572, -0.9096, -0.7862,  6.3077, -0.7849, -0.8311, -0.7623]],\n",
       "        grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc0.hyper_reduce[0](torch.tensor([0.0])), sc0.hyper_reduce[0](torch.tensor([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.2796],\n",
       "         [-0.3232],\n",
       "         [-0.2557],\n",
       "         [-0.0948],\n",
       "         [ 1.3129],\n",
       "         [-0.1455],\n",
       "         [-0.1758],\n",
       "         [-0.1736],\n",
       "         [-0.2873],\n",
       "         [-0.3027],\n",
       "         [-0.2337],\n",
       "         [-0.2279],\n",
       "         [ 1.6754],\n",
       "         [-0.2087],\n",
       "         [-0.2287],\n",
       "         [-0.1880]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.8079, -0.9030, -0.6230, -0.2134,  3.2586, -0.3532, -0.4448, -0.4817,\n",
       "         -0.8494, -0.8544, -0.6758, -0.5583,  4.6323, -0.5762, -0.6024, -0.5743],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc0.hyper_reduce[0].model[0].weight, sc0.hyper_reduce[0].model[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0., 1., -0., -0., -0., -0., -0., 0.],\n",
      "        [0., 1., -0., -0., -0., -0., -0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([[0., 1., -0., -0., -0., -0., -0., 0.],\n",
      "        [1., 0., -0., -0., -0., -0., -0., 0.],\n",
      "        [0., 1., 0., -0., -0., -0., -0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([[0., 0., -0., -0., -0., -0., -0., 1.],\n",
      "        [1., 0., -0., -0., -0., -0., -0., 0.],\n",
      "        [0., 0., 1., -0., -0., -0., -0., 0.],\n",
      "        [0., 1., 0., -0., -0., -0., -0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([[0., 0., -0., -0., -0., -0., -0., 1.],\n",
      "        [0., 0., -0., -0., -0., -0., -0., 1.],\n",
      "        [1., -0., -0., -0., -0., -0., -0., -0.],\n",
      "        [1., -0., -0., -0., -0., -0., -0., -0.],\n",
      "        [1., -0., -0., -0., -0., -0., -0., -0.]])\n"
     ]
    }
   ],
   "source": [
    "lam_ = 0.0\n",
    "for h,a in zip(sc0.hyper_reduce, sc.alpha_reduce):\n",
    "                a.data = torch.clone(h(torch.tensor([lam_]))) \n",
    "       \n",
    "fix_structure(sc)\n",
    "for a in sc.alpha_reduce:\n",
    "    print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0., 1., -0., -0., -0., -0., -0., 0.],\n",
      "        [0., 1., -0., -0., -0., -0., -0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([[0., 1., -0., -0., -0., -0., -0., 0.],\n",
      "        [1., 0., -0., -0., -0., -0., -0., 0.],\n",
      "        [0., 1., 0., -0., -0., -0., -0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([[0., 0., -0., -0., -0., -0., -0., 1.],\n",
      "        [1., 0., -0., -0., -0., -0., -0., 0.],\n",
      "        [0., 0., 1., -0., -0., -0., -0., 0.],\n",
      "        [0., 1., 0., -0., -0., -0., -0., 0.]])\n",
      "Parameter containing:\n",
      "tensor([[0., 0., -0., -0., -0., -0., -0., 1.],\n",
      "        [0., 0., -0., -0., -0., -0., -0., 1.],\n",
      "        [1., -0., -0., -0., -0., -0., -0., -0.],\n",
      "        [1., 0., -0., -0., -0., -0., -0., -0.],\n",
      "        [1., -0., -0., -0., -0., -0., -0., -0.]])\n"
     ]
    }
   ],
   "source": [
    "lam_ = 1.0\n",
    "for h,a in zip(sc0.hyper_reduce, sc.alpha_reduce):\n",
    "                a.data = torch.clone(h(torch.tensor([lam_])) )\n",
    "       \n",
    "fix_structure(sc)\n",
    "for a in sc.alpha_reduce:\n",
    "    print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def hyperloss(self, X, y, lam):\n",
    "        #logits = self.forward(X, lam)\n",
    "        penalty = 0\n",
    "        \n",
    "        for id, cell in enumerate(self.net.cells):\n",
    "            # можно не пробегать несколько раз, т.к. клетки одинаковы (С точностью до normal и reduce)            \n",
    "            \n",
    "            lam_ = lam\n",
    "            weights = [alpha(lam_) for alpha in self.hyper_reduce] if cell.reduction else [\n",
    "                alpha(lam_) for alpha in self.hyper_normal]\n",
    "            \n",
    "            weights = [F.softmax(w/self.t, dim=-1) for w in weights]\n",
    "            \n",
    "              \n",
    "            for edges, w_list in zip(cell.dag, weights):\n",
    "                for mixed_op, weights in zip(edges, w_list):\n",
    "                    for op, w in zip(mixed_op._ops, weights):                        \n",
    "                        for param in op.parameters():\n",
    "                            penalty += w*np.prod(param.shape)          \n",
    "            #penalty += lam_[0,0] * (torch.norm(self.net.linear.weight)**2 + torch.norm(self.net.linear.bias)**2)\n",
    "            #penalty += (1.0-lam_[0,0]) * (torch.norm(self.net.linear2.weight)**2 + torch.norm(self.net.linear2.bias)**2)\n",
    "            \n",
    "\n",
    "        # oleg return self.criterion(logits, y)   + penalty * lam[0,0] \n",
    "        return penalty \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc0 = sc0.cuda()\n",
    "sc0.t = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18132.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(18016.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17835.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17536.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16626.7168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(13917.3027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12224.7021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5902.5869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2624., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.3431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.4539e-18, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5506e-31, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1524e-42, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for r in range(-10, 10):\n",
    "    \n",
    "    print (hyperloss(sc0, 0, 0, torch.tensor([[(1.0*r)]]).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfigObj({'dataset': 'mnist', 'model_class': 'models.cnn_darts_hypernet.search_cnn_darts_hypernet.SearchCNNControllerWithHyperNet', 'name': 'mnist_darts_hypernet_gs', 'batch_size': '64', 'epochs': '50', 'validate_split': '0.5', 'quality': 'top1', 'use_train_quality': '0', 'seeds': '0', 'device': 'cuda', 'darts': {'layers': '1', 'init_channels': '8', 'input_channels': '1', 'n_classes': '10', 'n_nodes': '1', 'stem_multiplier': '3', 'sampling_mode': 'gumbel-softmax', 'initial temp': '1.0', 'delta': '-0.016', 'primitives': 'DARTS', 'optim': {'simple_alpha_update': '1', 'alpha_lr': '0.001', 'w_lr': '0.025', 'w_lr_min': '0.001', 'w_momentum': '0.9', 'w_weight_decay': '0.0', 'w_grad_clip': '5.0', 'alpha_weight_decay': '0.001'}}, 'hypernetwork': {'hidden_layer_num': '0', 'hidden_layer_size': '0', 'log10_lambda_min': '-8', 'log10_lambda_max': '-1', 'lambda sample num': '3'}})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 1.1084],\n",
       "         [-0.0756],\n",
       "         [-0.0762],\n",
       "         [-0.0475],\n",
       "         [-0.6884],\n",
       "         [-0.0391],\n",
       "         [-0.0297],\n",
       "         [-0.0831],\n",
       "         [ 1.0998],\n",
       "         [-0.0604],\n",
       "         [-0.0712],\n",
       "         [-0.0253],\n",
       "         [-0.6183],\n",
       "         [-0.0505],\n",
       "         [-0.0459],\n",
       "         [-0.0997]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 1.5646, -0.8272, -0.6284, -0.3190,  1.9144, -0.6870, -0.3635, -1.1838,\n",
       "          1.3121, -0.8585, -0.7832,  0.6159,  1.7367, -0.8624, -0.6465, -1.3189],\n",
       "        device='cuda:0', requires_grad=True))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc0.hyper_reduce[0].model[0].weight, sc0.hyper_reduce[0].model[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0, lam: -4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "  3%|▎         | 27/938 [00:02<01:27, 10.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-dc656a98e3d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/bakhteev/var_nas/models/cnn/search_cnn.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/bakhteev/var_nas/models/cnn/search_cnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bad sampling mode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/bakhteev/var_nas/models/cnn/search_cnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, weights_normal, weights_reduce)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_reduce\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mweights_normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/bakhteev/var_nas/models/cnn/search_cells.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, s0, s1, w_dag)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mw_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0ms_cur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_cur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/bakhteev/var_nas/models/cnn/search_cells.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mw_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0ms_cur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_cur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lam_ in [-4.0,  -1.0]:\n",
    "        lam = torch.tensor([10**lam_])\n",
    "        # создаем модель с обязательным указанием, что к структуре не применяется softmax\n",
    "        cfg = ConfigObj(basecfg_path)\n",
    "        cfg['darts']['sampling_mode'] = 'naive' \n",
    "        cfg['device'] = 'cuda'    \n",
    "        for s in seeds:\n",
    "            print (s)\n",
    "            sc0 = SearchCNNControllerWithHyperNet(**cfg)        \n",
    "            sc0.load_state_dict(torch.load(ckp_path.format(s)))                            \n",
    "            sc = SearchCNNController(**cfg)\n",
    "            \n",
    "            sc.net.load_state_dict(sc0.net.state_dict())\n",
    "            for h,a in zip(sc0.hyper_reduce, sc.alpha_reduce):\n",
    "                a.data = torch.clone(h(lam))                                            \n",
    "            fix_structure(sc)\n",
    "            \n",
    "            sc = sc.to('cuda')\n",
    "            optim = torch.optim.Adam(sc.weights())\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # дообучаем n эпох\n",
    "            print ('seed {}, lam: {}'.format(s, lam_))\n",
    "            for e in range(5):\n",
    "                for x,y in tqdm.tqdm(train_loader):\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()            \n",
    "                    optim.zero_grad()\n",
    "                    loss = sc.loss(x,y)\n",
    "                    loss.backward()\n",
    "                    optim.step()                              \n",
    "                \n",
    "                sc.eval()\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for x,y in tqdm.tqdm(valid_loader):\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()\n",
    "                    out = sc(x)\n",
    "                    correct += torch.eq(torch.argmax(out, 1), y).sum()\n",
    "                    total += len(x)\n",
    "                print (correct*1.0/total*1.0)\n",
    "                sc.train()\n",
    "            torch.save(sc.state_dict(), ckp_path.format(s)+'{}.fine'.format(lam_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 21, lam: -4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 43.77it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0960, device='cuda:0')\n",
      "seed 21, lam: -1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 44.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0967, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# смотрим качество модели, которое мы получили на обучении\n",
    "cfg = ConfigObj(basecfg_path)\n",
    "cfg['device'] = 'cuda'\n",
    "for lam_ in [-4.0,  -1.0]:\n",
    "    for s in seeds:\n",
    "        print ('seed {}, lam: {}'.format(s, lam_))\n",
    "        sc = SearchCNNController(**cfg)\n",
    "        \n",
    "        sc.load_state_dict(torch.load(ckp_path.format(s)+'{}.fine'.format(lam_)))\n",
    "        \n",
    "        sc = sc.to('cuda')\n",
    "        sc.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for x,y in tqdm.tqdm(valid_loader):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            out = sc(x)\n",
    "            correct += torch.eq(torch.argmax(out, 1), y).sum()\n",
    "            total += len(x)\n",
    "        print (correct*1.0/total*1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterList(\n",
       "    (0): Parameter containing: [torch.FloatTensor of size 2x8]\n",
       "    (1): Parameter containing: [torch.FloatTensor of size 3x8]\n",
       "    (2): Parameter containing: [torch.FloatTensor of size 4x8]\n",
       "    (3): Parameter containing: [torch.FloatTensor of size 5x8]\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oleg_torch",
   "language": "python",
   "name": "oleg_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
